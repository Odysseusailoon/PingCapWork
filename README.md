# PingCapWork
问题描述：
用1GB的内存计算100GB的URL中出现的TOP K个。

实现策略：
1.先用布隆过滤器找出重复URL，去重
2.再实现一个词频哈希表
3.最后维护一个大小为K的优先队列。

可能存在的bug及解决：
由于优先队列每次只可能维护K个大小的值，有个问题就是在一定区间[0,m]中，某个key的频率很小，
在优先队列执行插入的时候被忽略掉。但是在[m+1,end]的时候这个key突发聚集式增大，由于先前
我们没有保存，所以也并不知道这个key是否突然增大。
所以我们需要设计一个candidate的区域，存放那些频率非常低的url，优先队列插入的时候，对其
进行监听，隔一段时间看看有没有candidate的url增大，完成其中我用了一个“增长潜力”，就是在
candidate优先队列中，保存url的信息，其中引入accumulate因子，就是如果在这一段时间增长
潜力比highFreq的 频率最小的元素的增长潜力来的大，那么就合并到highFreq， highFreq队列
大小设置为2*DL，保证覆盖的范围是[0, DL] + [DL+1, 2DL]。这样循环不变式中，我们忽略的url
一直是cnt最小且增长潜力最小的。转正。

